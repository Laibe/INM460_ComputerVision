{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC and Logistic Regression with SIFT and SURF as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import bagoffeatures functions\n",
    "from bagoffeatures import bag_of_features,detect_and_compute, stack_descriptors,create_vocabulary\n",
    "# import external libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "root = Path('./') # define root path\n",
    "data_path = Path('data') # define data path\n",
    "much_face_path = data_path.joinpath('much_face')\n",
    "val_path = much_face_path.joinpath('val')\n",
    "train_path = much_face_path.joinpath('train')\n",
    "model_path = root.joinpath('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC + SURF\n",
    "SVC = SVM Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "featuretype = 'SURF'\n",
    "vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create (image,features) tuples and their class\n",
    "descriptions, image_classes = detect_and_compute(train_path,featuretype)\n",
    "# Stack descriptions into one large array\n",
    "stacked_desc = stack_descriptors(descriptions,featuretype)\n",
    "# Create vocabulary \n",
    "voc = create_vocabulary(stacked_desc,vocabulary_size)\n",
    "# Create bag of features \n",
    "im_bof = bag_of_features(descriptions,voc,vocabulary_size)\n",
    "# standardize \n",
    "stdSlr = StandardScaler().fit(im_bof)\n",
    "im_bof = stdSlr.transform(im_bof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Grid Search Parameter for SVM\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000,10000], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]\n",
    "   , 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000, 10000], 'kernel': ['rbf'], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate SVC model and fit \n",
    "svc = SVC()\n",
    "svc_grid = GridSearchCV(svc,param_grid)\n",
    "svc_grid.fit(im_bof, np.array(image_classes)) # fit bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'rbf', 'gamma': 0.0005}\n",
      "0.8177159590043924\n"
     ]
    }
   ],
   "source": [
    "# display best score and parameters \n",
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/SVC_SURF_gs_20180309.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store class_names\n",
    "class_names = list(set(image_classes))\n",
    "# save best model to disk \n",
    "svcbest = svc_grid.best_estimator_\n",
    "joblib.dump((svcbest, class_names, stdSlr, vocabulary_size, voc), 'models/SVC_SURF_gs_20180309.pkl', compress = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create (image,features) tuples and their class\n",
    "descriptions_val, image_classes_val = detect_and_compute(val_path,featuretype)\n",
    "# create bag of features and standard scaler\n",
    "im_bof_val = bag_of_features(descriptions_val,voc,vocabulary_size)\n",
    "im_bof_val = stdSlr.transform(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = svcbest.predict(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434504792332268"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy \n",
    "accuracy_score(image_classes_val,list(pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC + SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "featuretype = 'SIFT'\n",
    "vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create (image,features) tuples and their class \n",
    "descriptions, image_classes = detect_and_compute(train_path,featuretype)\n",
    "# Stack descriptions into one large array\n",
    "stacked_desc = stack_descriptors(descriptions,featuretype)\n",
    "# Create vocabulary \n",
    "voc = create_vocabulary(stacked_desc,vocabulary_size)\n",
    "# Create bag of features \n",
    "im_bof = bag_of_features(descriptions,voc,vocabulary_size)\n",
    "# standardize \n",
    "stdSlr = StandardScaler().fit(im_bof)\n",
    "im_bof = stdSlr.transform(im_bof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Grid Search Parameter for SVM\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000,10000], 'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]\n",
    "   , 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], 'C': [1, 10, 100, 1000, 10000], 'kernel': ['rbf']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate SVC model and fit \n",
    "svc = SVC()\n",
    "svc_grid = GridSearchCV(svc,param_grid)\n",
    "svc_grid.fit(im_bof, np.array(image_classes)) # fit bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0005, 'C': 10, 'kernel': 'rbf'}\n",
      "0.8118594436310396\n"
     ]
    }
   ],
   "source": [
    "# display best score and parameters \n",
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/SVC_SIFT_gs_20180310.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store class_names\n",
    "class_names = list(set(image_classes))\n",
    "# save best model to disk \n",
    "svcbest = svc_grid.best_estimator_\n",
    "joblib.dump((svcbest, class_names, stdSlr, vocabulary_size, voc), 'models/SVC_SIFT_gs_20180310.pkl', compress = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create (image,features) tuples and their class \n",
    "descriptions_val, image_classes_val = detect_and_compute(val_path,featuretype)\n",
    "# create bag of features and standard scaler\n",
    "im_bof_val = bag_of_features(descriptions_val,voc,vocabulary_size)\n",
    "im_bof_val = stdSlr.transform(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = svcbest.predict(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274760383386581"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy \n",
    "accuracy_score(image_classes_val,list(pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression + SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "featuretype = 'SURF'\n",
    "vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create (image,features) tuples and their class \n",
    "descriptions, image_classes = detect_and_compute(train_path,featuretype)\n",
    "# Stack descriptions into one large array\n",
    "stacked_desc = stack_descriptors(descriptions,featuretype)\n",
    "# Create vocabulary \n",
    "voc = create_vocabulary(stacked_desc,vocabulary_size)\n",
    "# Create bag of features \n",
    "im_bof = bag_of_features(descriptions,voc,vocabulary_size)\n",
    "# standardize \n",
    "stdSlr = StandardScaler().fit(im_bof)\n",
    "im_bof = stdSlr.transform(im_bof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Grid Search Parameter \n",
    "param_grid = [\n",
    "  {'C': [ 0.1, 1, 10, 100, 1000]},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.1, 1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate logistic regression model and fit \n",
    "logreg = LogisticRegression()\n",
    "#logreg.fit(im_bof, np.array(image_classes))\n",
    "# initiate SVC model and fit \n",
    "logreg_grid = GridSearchCV(svc,param_grid)\n",
    "logreg_grid.fit(im_bof, np.array(image_classes)) # fit bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.773792093704246\n"
     ]
    }
   ],
   "source": [
    "# display best score and parameters \n",
    "print(logreg_grid.best_params_)\n",
    "print(logreg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on full dataset\n",
    "logreg = LogisticRegression(C=10)\n",
    "logreg.fit(im_bof, np.array(image_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/LOGREG_SURF_gs_20180310.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store class_names\n",
    "class_names = list(set(image_classes))\n",
    "# save best model to disk \n",
    "logregbest = logreg_grid.best_estimator_\n",
    "joblib.dump((logregbest, class_names, stdSlr, vocabulary_size, voc), 'models/LOGREG_SURF_gs_20180310.pkl', compress = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create (image,features) tuples and their class (e.g. 004)\n",
    "descriptions_val, image_classes_val = detect_and_compute(val_path,featuretype)\n",
    "# create bag of features and standard scaler\n",
    "im_bof_val = bag_of_features(descriptions_val,voc,vocabulary_size)\n",
    "im_bof_val = stdSlr.transform(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = logregbest.predict(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8338658146964856"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy \n",
    "accuracy_score(image_classes_val,list(pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression + SIFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "featuretype = 'SIFT'\n",
    "vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create (image,features) tuples and their class (e.g. 004)\n",
    "descriptions, image_classes = detect_and_compute(train_path,featuretype)\n",
    "# Stack descriptions into one large array\n",
    "stacked_desc = stack_descriptors(descriptions,featuretype)\n",
    "# Create vocabulary \n",
    "voc = create_vocabulary(stacked_desc,vocabulary_size)\n",
    "# Create bag of features \n",
    "im_bof = bag_of_features(descriptions,voc,vocabulary_size)\n",
    "# standardize \n",
    "stdSlr = StandardScaler().fit(im_bof)\n",
    "im_bof = stdSlr.transform(im_bof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Grid Search Parameter \n",
    "param_grid = [\n",
    "  {'C': [ 0.1, 1, 10, 100, 1000]},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.1, 1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate logistic regression model and fit \n",
    "logreg = LogisticRegression()\n",
    "#logreg.fit(im_bof, np.array(image_classes))\n",
    "# initiate SVC model and fit \n",
    "logreg_grid = GridSearchCV(svc,param_grid)\n",
    "logreg_grid.fit(im_bof, np.array(image_classes)) # fit bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "0.7313323572474377\n"
     ]
    }
   ],
   "source": [
    "# display best score and parameters \n",
    "print(logreg_grid.best_params_)\n",
    "print(logreg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on full dataset\n",
    "logreg = LogisticRegression(C=10)\n",
    "logreg.fit(im_bof, np.array(image_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/LOGREG_SIFT_gs_20180310.pkl']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store class_names\n",
    "class_names = list(set(image_classes))\n",
    "# save best model to disk \n",
    "logregbest = logreg_grid.best_estimator_\n",
    "joblib.dump((logregbest, class_names, stdSlr, vocabulary_size, voc), 'models/LOGREG_SIFT_gs_20180310.pkl', compress = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create (image,features) tuples and their class (e.g. 004)\n",
    "descriptions_val, image_classes_val = detect_and_compute(val_path,featuretype)\n",
    "# create bag of features and standard scaler\n",
    "im_bof_val = bag_of_features(descriptions_val,voc,vocabulary_size)\n",
    "im_bof_val = stdSlr.transform(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = logregbest.predict(im_bof_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7827476038338658"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy \n",
    "accuracy_score(image_classes_val,list(pred_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
